재택수업후 급증한 트래픽으로 응답시간 10초가 됨

원인 : DB문제

사용자가 조금만 증가해도 CPU 사용률 90% 초과 ⇒ 쿼리 실행시간 느려짐 ⇒ 서버 응답 시간 느려짐

원인 : 호출 빈도가 높은 기능이 풀 스캔 유발

<aside>
💡

### DB 성능이 중요한 이유

DB 성능 ⇒ 연동하는 모든 서버 성능에 영향을 줌

</aside>

## 조회 트래픽을 고려한 인덱스 설계

일반적인 시스템에서는 조회 트래픽이 많이 발생

카테고리별로 분류하는 쿼리 ⇒ ✨⭐️which means where 절에 카테고리가 사용되는것

⇒ 카테고리에 인덱스가 없다면 

⇒ 사내 게시판이라면 문제가 없다

⇒ 하지만 인기 커뮤니티 사이트에서 카테고리별로 인덱스가 걸려있지 않다면

⇒ 테이블 풀 스캔이 발생

⇒ 동시에 테이블 풀 스캔이 발생하면서 db 장비의 cpu 사용률이 100%

 ⇒ 성능에 심각한 문제

✨⭐️쿼리 튜닝 책으로 스터디 했을때도 where 절에 자주 사용되는 것은 인덱스가 있는것이 좋다! 고 함 물론 모든것은 case by case…

풀 스캔이 발생하지 않게 하려면 조회 패턴을 기준으로 인덱스를 설계해야 한다

게시판의 경우 카테고리 별로 조회하는 패턴 ⇒ 카테고리 칼럼에 인덱스를 추가

내가 작성한 글 목록 조회 ⇒ ✨⭐️which means where 절에 writerId = 10가 사용되는것

도 자주 사용되는데 이때도 풀 스캔이 발생하지 않게 하려면 writeId 칼럼을 포함한 인덱스를 생성해야 한다 !!

```java
select id, category, writerId, title, content from article
where writerId = 10 order by id desc liit 10, 10
```

```java
select id, category,writeId, title, content from article
where title like '%검색어%' order by id desc limit 10
```

중간에 포함된 단어를 검색하기 위한 like 조건은 풀스캔을 유발!! 

⇒ 선택도가 정말 낮아지기 때문…

⇒ 앞에 %가 붙으면 배제하고 시작할 수가 없다.. 무조건 풀스캔

엘라스틱서치 등 검색엔진을 사용하면 DB를 사용하지 않고 검색 기능 구현 가능

but 별도의 검색 엔진을 구현하기 힘든 상황이라면 
DB가 제공하는 전문 검색 기능 사용을 고려해보자

Oracle Text나 MySQL의 FULLTEXT 인덱스를 사용하면 풀 스캔 없이 문자열 검색 쿼리를 실행할 수 있다

<aside>
💡

전문 검색 인덱스

단어 또는 문장 단위로 텍스트를 분석하여, 효율적으로 검색할 수 있게 돕는 인덱스

나의 의문점🤔 : 

그럼 전문 검색 인덱스는 몽고디비에서 텍스트 검색에 사용하듯이 특별한 트리 형태로 모든 단어가 추출되어서 역인덱스를 저장하고 있는건가?

답 : YES!

전문 검색 인덱스(Full-text Index)는 몽고DB에서 쓰이는 텍스트 검색과 마찬가지로 보통 **역 인덱스(inverted index)** 구조를 기반으로 한다고 한다!

회사에서 OpenSearch(ElasticSearch) 사용하는데 거기서 analyzer가 동작하는거랑 비슷한 것 같다!

| DBMS | 인덱스 유형 | 자료구조 | 동작 방식 요약 | 주요 특징 |
| --- | --- | --- | --- | --- |

| **MongoDB** | `text` 인덱스 | 역색인 (Inverted Index) + B-Tree | 단어 추출 → 소문자화, 불용어 제거 → 역색인 구성 → `$text: {$search: ...}` | 기본 다국어 분석기, 점수 기반 정렬, stemming 지원 |
| --- | --- | --- | --- | --- |

| **MySQL** | `FULLTEXT INDEX` | 역색인 (Inverted Index) | `MATCH(col) AGAINST('query')` 로 검색, Boolean 모드 지원 | 최소 단어 길이(기본 4자), 불용어 처리, InnoDB는 트랜잭션과 병행 사용 가능 |
| --- | --- | --- | --- | --- |

| **PostgreSQL** | `GIN` + `tsvector` | GIN (Generalized Inverted Index) | `to_tsvector()`로 텍스트 처리 → `to_tsquery()`로 검색 | 강력한 언어 지원, boolean/phrase query, ranking 가능 |
| --- | --- | --- | --- | --- |
</aside>

### 단일 인덱스와 복합 인덱스

일평균 방문 회원이 10만명이고 평균 5번의 활동을 하는 activityLog 테이블

하루에 50만건의 데이터가 쌓임

한달이면 1500만건의 데이터가 쌓임

대규모 데이터는 아니지만 작은 데이터도 아니다~ 

!!! 용도에 알맞은 인덱스가 없으면 조회 성능에 문제가 발생할 수 있음

```java
select * from activityLog 
where userId = 123 and activityDate = '2024-07-31'
order by activityDatetime desc;
```

단일 인덱스: userId만 인덱스로 사용

복합 인덱스: userId,activityDate를 인덱스로 사용

사용자당 가질 수 있는 데이터가 얼마나 될지 가늠해보면 어떤 인덱스를 사용해야 할지 판단하는데 도움이 됨

일주일에 하루정도 방문하고 평균 활동 데이터가 5건이면 단일 인덱스로도 ㄱㅊ

회원들의 활동성이 좋다면 복합 인덱스 사용을 고려해야한다

### 통계 추출

activityLog 테이블은 통계추출으로도 사용가능

```java
select activityDate, activityType, count(activityType)
from activityLog
where activityDate = '2024-07-28'
group by activitytype;
```

전체 데이터를 풀 스캔하지 않으려면 activityDate 칼럼을 인덱스로 사용해야 함

activityType 칼럼을 인덱스에 포함시키느냐 마느냐 !

### 선택도가 높은 칼럼을 골라야 한다~

선택도 선택도 하는데 처음에 잘 안 와닿았지만 공부하다보니 결국 그냥 “데이터를 많이 걸러내는” 컬럼을 뜻하는 거 같았다! 

쿼리 튜닝 스터디에서 내가 복합 인덱스 파트 발표했었던 내용이 기억나서 살짝 첨부

<aside>
💡

### 복합 인덱스 사용 시 핵심 원칙

1. **선택도(Selectivity) 원칙**
    - 높은 선택도(데이터를 많이 걸러내는) 컬럼을 앞에 배치
    - '같다(=)' 조건은 일반적으로 '범위' 조건보다 선택도가 높음(당연하다)
2. **검색 효율성 원칙**
    - 인덱스 선두 컬럼이 정확히 일치할 때 다음 컬럼도 검색 범위 축소에 기여
    - 인덱스 선두 컬럼이 범위 조건일 때 다음 컬럼은 검색 범위 축소에 기여하지 못함
3. **데이터 정렬 원칙**
    - 복합 인덱스는 선언된 컬럼 순서대로 데이터를 정렬
    - 정렬 순서가 쿼리 조건과 일치할 때 최고의 성능 발휘
</aside>

<aside>
💡

### 선택도가 이렇게 중요합니다

CASE 1 :  같다 조건, 범위 조건 순서로 인덱스 구성

```java
1. 20170301 - CUS_0001 (A0001) ← 불필요한 레코드
2. 20170301 - CUS_0002 (A0010) ← 불필요한 레코드
3. 20170301 - CUS_0075 (A0011) ✓ 필요한 레코드
4. 20170301 - CUS_0099 (A0002) ← 불필요한 레코드
5. 20170302 - CUS_0002 (A0014) ← 불필요한 레코드
6. 20170303 - CUS_0075 (A0015) ✓ 필요한 레코드
7. 20170304 - CUS_0001 (A0006) ← 불필요한 레코드
8. 20170304 - CUS_0075 (A0007) ✓ 필요한 레코드
9. 20170304 - CUS_0099 (A0012) ← 불필요한 레코드
```

CASE 2:  범위 조건, 같다 조건 순서로 인덱스 구성

```java
1. CUS_0075 - 20170228 (A0004) ← 조건에 맞지 않음
2. CUS_0075 - 20170301 (A0011) ✓ 필요한 레코드
3. CUS_0075 - 20170303 (A0015) ✓ 필요한 레코드
4. CUS_0075 - 20170304 (A0007) ✓ 필요한 레코드

```

</aside>

선두 컬럼(where절 첫 조건)에 인덱스가 없으면 테이블 풀스캔이 발생하는 원리도 잘 보여주는 것 같다!

### 커버링 인덱스 활용하기

인덱스에서 모든 필요한 칼럼을 들고 돌아갈 수 있다면 실제 테이블에 접근하지 않아도 되어서 실행 시간이 대폭 단축된다!

<aside>
💡

B-Tree 인덱스의 기본 구조

B-Tree 인덱스는 루트 노드, 브랜치 노드, 리프 노드로 구성됨

데이터베이스가 인덱스를 이용해 데이터를 찾는 과정은 다음과 같다

1. 루트 노드에서 시작
2. 브랜치 노드를 통해 리프 노드로 이동
3. 리프 노드에서 필요한 데이터를 스캔
4. 리프 노드의 RID(Row Identifier)를 이용해 실제 테이블 데이터에 접근
</aside>

커버링 인덱스를 사용한다면 실제 테이블 데이터 접근 없어짐 ⇒ 빨라짐!

### 인덱스는 필요한 만큼만 만들기

쿼리 튜닝 스터디할때 인덱스를 너무 많이 관리해서 인덱스의 KB가 원본 데이터를 넘어서는… 막장 상황을 보았었다 !!!

인덱스 관리 비용도 잘 생각하자!

같은 인덱스 또 추가하면 관리 비용만 두배가 되는 것도 조심~

## 조회 성능 개선 방법

미리 집계하기 ⇒ 카운트 칼럼!

- 각 설문은 질문이 4개로 고정되어있음
- 회원은 각 설문조사마다 좋아요를 할 수 있음
- 설문조사목록을 보여줄 때 답변 수와 좋아요 수를 표시

실시간 집계 ⇒ 서브쿼리

```sql
SELECT 
    s.id, 
    s.subject, 
    (
        SELECT COUNT(*) 
        FROM answer a 
        WHERE a.surveyId = s.id
    ) AS answerCnt, 
    (
        SELECT COUNT(*) 
        FROM liked l 
        WHERE l.surveyId = s.id
    ) AS likeCnt
FROM 
    survey s
ORDER BY 
    s.id DESC
LIMIT 30;

```

미리집계 ⇒ 카운트 칼럼 추가

비정규화해도 괜찮나요? 성능의 획기적인 개선을 위해서라면 어느정도 허용할 수 있다

좋아요 개수가 단시간동안 좀 차이나는것은 성능의 효율성에 따르면 감수할만한 리스크…

⇒ 저걸 보면서 누적합같다고 생각했다~

<aside>
💡

### 동시성 문제는 없을까?

다음 쿼리를 동시에 5개 클라이언트가 실행하면 어떻게 될까?

```sql
update survey set answerCnt = answerCnt + 1 where surveyId = 1;
```

DB가 이 쿼리를 원자적 atomic 연산으로 처리하면 answerCnt는 5만큼 증가

원자적 연산으로 처리하지 않으면 answerCnt 값이 어떻게 될지 예측 불가능

트랜잭션 격리 수준에 따라 그리고 사용하는 DBMS에 따라 이 쿼리는 원자적으로 실행되기도 하고 그렇지 않기도 함

MySQL의 InnoDB는 원자적 처리를 보장한다!

증가/감소 쿼리를 사용할 때는 DBMS 가 지정한 트랜잭션 격리 수준에서 원자적으로 처리하는지 꼭 체크하도록 하자! 

### ✨⭐️원자적으로 처리하지 않을 경우 동시성 문제 해결법 러프하게

- 트랜잭션 격리 수준이나 락을 통해 해결
- 더 정밀하게 관리하려면 비관적 락 또는 낙관적 락을 사용
- Redis나 메시지 큐를 활용한 외부 처리 방식도 가능
</aside>

### 페이지 기준 목록 조회 대신 id 기준 목록 조회 방식 사용하기

### 아이디(인덱스가 있는 칼럼) 으로 다음 데이터부터 10개 읽어오도록 하기

⇒ 진짜 대박 효율적일듯 

AKA 커서 기반 페이지네이션… Cursor-based pagination…

페이지 기준으로 조회하게될때 

99990번째 부터 10개 가져와 라고 하면

DB는 뭐가 99990번째인지 모르기 때문에 99990번째까지 읽고있다고 한다…☠️☠️☠️

이때 전에 받은 데이터의 id(id는 인덱스가 존재할 것이므로…)부터 다음 값을 조회하게 된다면?!

인덱스를 통해 빠른 조회가 가능하다!!!

정말 획기적인 아이디어다

Tip: 그리고 다음이 있는지 없는지도 확인하고 싶다면 11개를 반환해서 11번째가 있을 경우 다음이 존재한다고 판단

### 조회 범위를 시간 기준으로 제한하기

- 날짜 range 쿼리 하게함, 복합인덱스에 포함시킴
- 사용자의 니즈가 적고 기능에 별 문제가 없다면 최신 데이터만 제공하는것이 성능에 좋다

### 전체 개수 세지 않기~

카운트 쿼리 ⇒ 테이블 풀스캔 발생…

나도 매번 카운트쿼리 따로 세어서 resultDto에다 채워줄때머다 현타왔었음…

위에서 페이지네이션을 해서 10개만 돌려보내면 뭐해요?

바로 아랫줄에서 카운트쿼리 날려서 풀스캔 뜨고 있는데?

하지만 ppt로 만들어진 UI정의서를 거스를수도 없고 내 의견을 낼 수도 없다는것!

✨⭐️💡그래서 생각해본 나름의 해결방안…

앞에 나온 내용처럼 검색 조건이 뭔가 카테고리별 이런식으로 일정하다면? 

누적합 카운터(캐시 st)를 하나 둬서 그걸로 총갯수를 사용하는 방안… 도 생각을 해 보았다… 

하지만 우리 플젝은 한 페이지당 검색조건이 평균 12개정도 되고 그걸로 정말 다양한 조합이 나올 수 있어서 불가능할 것 같다!

다른 사람들은 어떻게 생각하는지 궁금하다…

### 평소 패턴을 숙지하고 이상징후찾기

모니터링 툴로 평소 패턴을 그래프 등으로 보다가 모양이 이전과 달라지기 시작하면(응답 속도가 증가하는 일이 일어난다면) 바로 쿼리 분석 들어가기~

향후 문제가 될 수 있는 징후를 조기에 발견하여 조치하면 장애를 막을 수 있다~

### 오래된 데이터 삭제 및 분리 보관하기

- 오래된 데이터는 대부분의 경우 보지 않는다(나의 쇼핑 이력이나 로그인 시도 이력 등)
- 따라서 성능을 위해 기능에 큰 문제가 없고 사용자의 니즈가 적은 경우 삭제처리…
- 및 분리 보관 처리…

단편화와 최적화 내용 더 보기

<aside>
💡

### 삭제의 단점 ⇒ 단편화 ⇒ 해결책: 최적화

- `DELETE` 쿼리는 **데이터를 논리적으로만 삭제**
- 실제 디스크 공간은 줄지 않고, **삭제된 공간은 내부적으로 재사용**

## 단편화(Fragmentation)

- 데이터가 **추가·삭제·수정**되는 과정에서 **공간이 비효율적으로 배치**되는 현상
- 디스크에 **빈 공간이 흩어짐**
- 관련 데이터가 **연속적으로 저장되지 않아 I/O 성능 저하**
- 실 사용 데이터보다 **더 많은 디스크 공간을 차지**함

## 해결책: 테이블 최적화(Optimize)

- 최적화는 **데이터를 재배치**해서 단편화를 줄이고,
- **디스크 공간도 회수**하여 실제 사용량을 줄임

이걸 어떻게 하냐면

내부적으로 테이블 복사해서 새 테이블을 만들게 함 ⇒ 물리적으로 연속된 위치에 데이터들이 저장된다!

</aside>

### Db 장비 확장하기

- 수직 확장 = TAKE MY MONEY
- 수평 확장

DB를 수평으로 확장하면 DB가 처리할 수 있는 트래픽을 늘릴수 있다

조회 트래픽 비중이 높은 서비스 ⇒ 주 DB–복제 DB (Primary–Replica) 구조 ⇒ 처리량을 효과적으로 증가시킴

BUT!

- 한 번 만든 DB를 줄이기는 쉽지 않음
- DB 서버는 API 서버에 비해 몇 배 이상 사양이 좋은 장비를 사용 ⇒ 가격도 비쌈

증가한 고정 비용이 감당 가능한지 잘 생각해보고 늘리자…

### 별도 캐시 서버 두기

- DB만으로 모든 트래픽을 처리하기 힘들어질 때
- 성능 개선 방법을 모두 적용했을때
- 비용 이슈로 DB를 더 늘리기도 힘들 때

캐시 서버를 구성해보아요~

DB 확장보다 적은 비용으로 늘어난 트래픽을 감당해낼 수 있음

## 알쓸신잡

### 쿼리 타임아웃

- 응답 시간이 늘어나면 처리량은 줄고, 사용자 재시도가 서버 부하를 키운다.
- 재시도가 반복되면 동시 요청 수가 기하급수적으로 증가해 서버가 과부하된다.
- 쿼리 타임아웃을 설정하면 일정 시간 초과 시 요청을 강제 종료해 부하를 억제할 수 있다.
- 타임아웃 설정은 기능 특성에 따라 달리 적용해야 한다.
- 단순 조회는 짧게, 결제 등 중요 처리는 충분히 길게 설정해야 한다.(결제처리하다 타임아웃나면 후속처리와 데이터 정합성 관리가 더 귀찮을 수 있으므로)

### 상태 변경 기능은 복제 DB에서 조회하지 않기

DB–복제 DB 구조를 사용할 때 변경은 주 DB를 사용하고 조회는 복제 DB를 사용한다.

🔥🚨그러나 모든 SELECT 쿼리를 무조건 복제 DB에서 실행하면 안 된다!!!❌

- 주 DB와 복제 DB는 복제 지연으로 인해 일시적으로 데이터가 일치하지 않을 수 있다.
- 주 DB에서 데이터가 변경된 직후 복제 DB에서 조회하면 변경 내용이 반영되지 않을 수 있다.
- 복제 DB의 SELECT 쿼리는 실시간성이 중요한 상황에서 잘못된 결과를 반환할 수 있다.
- 주 DB의 트랜잭션이 끝나기 전에 복제 DB에서 데이터를 조회하면 정합성 문제가 생긴다.

🔥🔥INSERT, UPDATE, DELETE와 관련된 SELECT(이것을 하면서 체크하는 쿼리)는 복제 DB가 아닌 주 DB에서 수행해야 데이터 불일치로 인한 문제를 방지할 수 있다

<aside>
💡

### INSERT, UPDATE, DELETE와 관련된 SELECT의 경우 생각해봄

### 1. **회원 가입 시 이메일 중복 확인**

- 사용자가 방금 이메일로 회원가입 했는데, 아직 복제 DB에 반영 안 됐으면 **중복 검사를 통과해버림**
- → **중복 가입 가능** or "이미 가입한 이메일입니다" 메시지가 누락됨

---

### 2. **닉네임 중복 확인 후 업데이트**

- 다른 사용자가 닉네임을 선점한 직후인데, 복제 DB에선 아직 반영 안 됐다면 **중복 허용 오류** 발생

---

### 3. **게시물 좋아요 추가 전 중복 체크**

- 이미 좋아요를 누른 기록이 주 DB에 있는데 복제 DB에는 반영 안 됐다면, **중복 좋아요가 가능**

---

### 4. **재고 수량 확인 후 주문 처리**

- 재고 감소가 주 DB에선 이미 반영됐지만 복제 DB엔 반영 안 됐다면, **잘못된 재고로 주문이 통과**

---

### 5. **삭제 전 존재 여부 확인**

- 사용자가 방금 댓글을 삭제했는데 복제 DB에서 조회하면 **이미 삭제된 걸 다시 삭제 시도해서 에러**

---

</aside>

<aside>
💡

### 주 DB와 복제 DB간의 데이터 복제는 트랜잭션 커밋 시점에 발생

WHY?🤔

당연하다
롤백될 수 있으니 확정된 데이터만 전파해야 하기 때문이다

</aside>

### 배치 처리 실행 시간 증가

- 커버링 인덱스 활용
- 검색 조건을 짧게 잡아 한개씩 배치처리한 후 합치기
- ✨⭐️저렇게 하면 누적합(prefix sum) 식으로도 가능해짐 ⇒ 오늘치만 집계해서 총 데이터 업데이트 가능!!

DB장비 확장이 어렵다면 배치 처리를 하자..

⇒ 

<aside>
🧐

🤔 예전에 궁금했던 점
다른 회사 분들이랑 스터디를 해봐도 모두 배치처리를 새벽에 돌린다 고 하는데

그건 우리나라 시점으로 새벽인것이고

글로벌 서비스의 경우에 어딘가는 항상 낮인건데

배치를 어떻게 돌리는지… 궁금했다

그런 경우는 그냥 DB를 확장하는 수밖에 답이 없나?

AI가 발달하면 DB 사용량 줄어드는 순간에 배치돌려주고 막 이렇게는 안되려나

</aside>

### 타입이 다른 칼럼 조인 주의

```sql
select u.userId, u.name, p.* from user u, push p 
where u.userId = 145 and u.userId = p.receiverId and p.receiverType = ‘MEMBER’ 
order by p.id desc 
limit 100;
```

user 테이블: 유저 정보

userId: Integer

push 테이블: 푸시 발송 내역을 저장

receiverType 칼럼: 푸시 수신 타입

receiverId 칼럼: varchar(수신 타입에 따라 식별자 타입이 다르기 때문에)

⇒ 

<aside>
🧐

저게 왜 저런지 이해 못했음 receiverId에다가 Integer로 넣어주면 왜 안되는건데? 왜??

</aside>

아무튼 저런 상황이라고 치고

수신 대상에 대한 푸시 목록을 자주 조회하기 때문에 receiverId 칼럼에 인덱스를 추가

!!! 하지만 인덱스를 사용하지 못할 수도 있다

- DB 내부적으로 타입 변환 사용 ⇒ 인덱스 사용 불가

🤔이 얘기를 들으니

⇒ 회사 플젝할때 오픈서치 타입 매핑 잘못 되어있었던 예시가 생각이 나네요…

⇒ 그리고 어디서는 botCode를 기준으로 쓰고 어디서는 botId를 사용해서 그냥 커버링 인덱스마냥 파라미터 값으로만 조회할수도 있었던 것을 굳이굳이 botRepository까지 가서 그 코드를 쓰는 봇의 id를 또 추출해와야 했던 예시…

⇒ 제발 프로젝트 전체적으로 기준이 되는 필드는 하나만 써줬으면 좋겠습니다

⇒ 문서화가 이래서 중요한 것 같다… 서로 소통도 잘 하고 뭐든 문서화로 매뉴얼처럼 되어있으면 각자 어떻게 구성되어 있는지 업무 파악하기도 좋아서…

비교 대상의 칼럼을 맞추면 변환과정도 생략되고 인덱스도 활용할 수 있어서 실행시간이 줄어든다~

```java
select u.userId, u.name, p.*
from user u, push p
where u.userId = 145
and cast(u.userId as char character set utf8mb4) collate 'utf8mb4_unicode_ci' =
p.receiverId
and p.receiverType = 'MEMBER'
order by p.id desc
limit 100;
```

- 문자열 타입을 비교할때는 칼럼의 캐릭터셋이 같은지도 확인해야 한다
- 캐릭터셋이 다르면 그 자체로도 변환이 발생할 수 있기 때문이다

<aside>
🧐

### ??? 캐릭터셋이 어케 다를수가 있지???

MySQL에서 `VARCHAR` 같은 문자열 타입을 사용할 때, 겉으로 보기엔 같아 보여도 내부적으로는 캐릭터셋(character set)과 정렬 규칙(collation)이 다를 수 있어. 예를 들어, 하나의 컬럼은 `utf8mb4`이고 다른 하나는 `latin1`이거나, 혹은 둘 다 `utf8mb4`지만 정렬 방식이 `utf8mb4_general_ci` vs `utf8mb4_unicode_ci`처럼 다를 수 있어. 이 경우 문자열 비교가 일어날 때 자동으로 형변환이나 캐릭터셋 변환이 발생하게 되고, 그 순간 인덱스를 사용할 수 없게 돼서 쿼리 성능이 급격히 떨어질 수 있어.

특히 문제가 되는 건 숫자와 문자열을 비교할 때인데, 예를 들어 `userId`는 정수형이고 `receiverId`는 문자열인 경우, 비교를 위해 `CAST(userId AS CHAR)` 같은 형변환을 하게 되면 변환 비용이 발생하고 역시 인덱스는 무시돼. 그래서 성능을 고려한다면 애초에 두 값을 같은 타입으로 맞추는 게 제일 좋고, 문자열로 비교해야 한다면 캐릭터셋과 collation까지 일치시켜야 인덱스가 제대로 활용돼.

</aside>

### 테이블 변경은 신중하게

데이터가 많은 테이블에 새로운 칼럼을 추가하거나 기존 Enum 타입 칼럼을 변경할때는 매우 주의해야한다

테이블 변경시 주의해야 하는 이유 = DB의 테이블 변경 방식

테이블을 변경하는동안 락이 걸리기 때문에 다운타임이 생기게된다…

MySQL의 경우에는 테이블을 변경할 때 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤 복사가 완료되면 새 테이블로 대체

⇒ 복사 과정에서 DML작업이 모두 잠긴다

⇒ 복사 시간만큼 다운타임 발생

<aside>
🧐

### DML을 허용하면서 테이블을 변경하는 기능도 있지만 ⇒ 그건 어떻게 동작하는 것일까? ⇒ 이것이 아래에 나오는 온라인 DDL!!!

- 일반적으로 DDL(테이블 변경)은 **락을 걸고 단일 세션만 작업**
- 특정 조건과 내부 동작 방식 덕분에 **DML과 병행 처리**가 가능해지는 거\

### MySQL 5.6 이상에서는 많은 `ALTER TABLE` 문이 `INPLACE` 방식으로 동작

- 테이블 전체를 복사하지 않고 메타데이터나 인덱스를 **분리된 영역에 비동기 처리**
- DML이 발생하면 **변경 로그(change buffer)를 별도로 기록**해서 DDL 완료 후 병합
- 작업 중에는 **일부 잠금은 짧게만 걸리고**, 전체 테이블 락은 피함

### PostgreSQL`ADD COLUMN` with DEFAULT

- 내부적으로 기존 행은 새 컬럼을 갖고 있다고 간주
- 실제로는 디스크에 쓰지 않고 조회 시 기본값을 리턴하는 식으로 최적화
</aside>

아무튼 저게 항상 가능한 것은 아니라서 데이터가 많은 테이블은 점검 시간을 잡고 변경하는 경우가 많다고 한다

회사에 dba가 있다면 서비스 제공중에도 가능한지 아니면 점검을 잡아 변경할지 판단해준다

<aside>
💡

서비스를 멈추게 한 테이블 변경

수천만건의 데이터가 있는 테이블에서 ENUM타입을 변경하다가 서비스가 중단되어버림

⇒ 🤔나의 생각: 그래서 대부분 Enum 사용을 꺼리고 DB에는 String화해서 넣지 않나

DB 담당자가 열거 타입 칼럼을 변경할때 온라인 DDL을 사용하지 않았고

### 🤔온라인 DDL이 뭘까?

서비스를 중단하지 않고(online), DML(조회·삽입·수정·삭제)을 계속 허용하면서 테이블 구조를 변경할 수 있는 DDL 기능

- DBMS가 **변경 대상 외의 데이터는 건드리지 않고**,
    
    **변경 내역만 따로 기록하고 병합**하는 방식으로 동작함
    
- 인덱스를 생성할 때도, **기존 데이터는 그대로 두고** 새 인덱스를 백그라운드에서 생성한 뒤 교체

점검모드로 전환하고 몇시간 후에 주DB가 변경이 끝났는데 그때부터 복제DB 시작해서 8시간동안 서비스 중단 ⇒ 데이터 보정과 고객 보상같은 후처리시간 필요해졌다고 함

</aside>

### DB 최대 연결 개수

- API 서버는 세대
- 트래픽이 증가하고 있어서 수평 확장이 필요
- DB서버의 CPU 사용률은 20%수준 ⇒ 여유있음

트래픽 증가를 감당하기 위해 API 서버 추가

⇒ 새로 추가한 API 서버에서 DB 커넥션 생성에 실패한다면

⇒ DB 서버 자원에는 여유가 있지만 DB 사용이 불가능

DB의 최대 연결 개수가 100개임

API 서버의 커넥션 풀 개수는 30개 ⇒ 서버가 4대 ⇒ 120개

20개의 커넥션은 얻어지지 못하고 연결 실패가 발생한다~

⇒ 이럴때는 최대 연결 개수를 늘려줘야 함

BUT!!! DB서버의 CPU사용률이 70%이상으로 높다면 연결 개수를 늘리면 안된다

연결 수가 많아질수록 DB 부하는 증가하고 성능 저하가 발생가능

먼저 캐시 서버 구성/ 쿼리 튜닝 등의 조치를 통해 DB 부하를 낮춘 후 필요할때 연결 개수를 늘려야 한다

## 실패와 트랜잭션 고려하기 ⇒ 꼭 같이 롤백되어야 하는 단위로만 묶기

비정상 상황에서의 트랜잭션 처리를 반드시 고민해야 한다

트랜잭션을 고려하지 않고 코드를 작성하면 데이터 일관성에 문제가 생길 수 있기 때문이다

빈번실수 1. 트랜잭션 없이 여러 데이터를 수정

데이터를 변경하는 코드는 트랜잭션 범위 안에서 실행하는게 당연해보이지만 실수로 빠트리는 경우도 있다

트랜잭션의 시작과 종료 경계를 명확히 설정했는지 반드시 확인하자

트랜잭션없이 DB를 변경하는 예시

1. 애플리케이션이 DB에 연결
2. select * from contract where …
3. insert contract values (…)
4. update userStatus set …

과정4에서 실패하게 되면 contract 데이터와 userStatus 데이터 사이에 일관성 문제가 생김

트랜잭션 경계를 명확히 설정해야한다… 같은 데이터 변경으로 영향받는 범위를 하나의 트랜잭션으로 묶어야 할 것 같음

과정4가 실패하면 contract는 이미 추가되었는데 userStatus는 업데이트가 안되고

사용자는 상태가 반영되지 않으니까 계속 시도하는데 이미 contract테이블에 존재하니까 계약 진행이 불가능하게 된다

<aside>
💡

### 일부 기능에서 오류가 나도 트랜잭션을 커밋해야하는 상황

회원가입기능

member 테이블에 회원정보를 추가 ⇒ 가입 환영 메일을 전송

```sql
@Transactional

public void join(JoinRequest join){

…

memberDao.insert(member);//DB에 데이터 추가

mailClient.sendMail(…);//메일 발송

}
```

</aside>

메일 서버에 일시적인 문제가 있어서

sendMail()에서 RuntimeException이 발생

⇒ 스프링의 @Transactional은 런타임 예외가 발생하면 전체 트랜잭션을 롤백한다

⇒ 위 코드는 DB에 회원 데이터를 정상적으로 추가했더라도 메일 발송중 예외가 발생하면 회원가입 전체가 실패

그러나 환영 메일을 못 받는게 회원가입 절차를 모두 취소시키고 다시 시킬만큼 중요한 일일까?

그렇지 않을 것이다…

메일 발송에 실패하더라도 회원 가입은 정상 처리되기를 원한다면 메일 발송 오류는 별도로 처리해서 무시해야 한다

```java
@Transactional
public void join(JoinRequest join){

	…

	memberDao.insert(member);//DB에 데이터 추가
	try{
		mailClient.sendMail(...);
	} catch (Exception e){
		//메일 발송 오류 무시하고
		//로그로 기록해서 모니터링~
	}
}
```

⇒ 

🤔 근데 여기서 드는 나의 생각 

나라면 저기다가 try-catch를 안 하고 그냥 AOP로 에러를 핸들링하면서

Transactional 범위를 꼭 필요한 구간에만 넣는 식으로 처리했을 것 같다

메서드를 추가로 분리해서

```java

public void join(JoinRequest join){
	insertMember(member);
	sendMail(member);
}

@Transactional
private void insertMember(member){
	memberDao.insert(member);//DB에 데이터 추가
}

private void sendMail(member){
	mailClient.sendMail(...);
}
혹은
private void sendMail(member){
	try{
		mailClient.sendMail(...);
	} catch (Exception e){
		//메일 발송 오류 무시하고
		//로그로 기록해서 모니터링~
	}
}
```

다른 사람들은 어떻게 생각하는지 궁금하다!

그리고 나도 코드를 작성할 때 저 메일 전송처럼 사소한 에러가 발생하는것은 에러를 미리 잡아서 log.info로만 로깅하고 넘어가고 있는데

그것의 try-catch문이 점점… 덕지덕지… 상당히 못생겨져서 이것도 뭔가 AOP로 처리하든지 방법을 찾으려고 하는중…
