## 동기 연동과 비동기 연동

동기 ⇒ 순차적으로 꼭 실행되어야만 할 때

- 프로그램의 흐름 직관적 이해 가능
- 디버깅 용이
- 외부 서비스까지 동기로 처리하면 응답시간 up

비동기 ⇒ 다음 작업 진행에 굳이 이전 작업이 필요없을때

- 비동기 처리해도 문제없을때
    - 쇼핑몰 주문 들어오면 판매자에게 push ⇒ 연동 실패해도 영향 없음
    - 포인트 지급 ⇒ 실패시 수동으로 처리
    - 컨텐츠 등록시 검색 서비스 연동 ⇒ 실패시 수동으로 처리
    - 인증메시지 sms 발송 ⇒ 실패시 재시도 가능

비동기 처리의 5가지 방법

- 별도 스레드 실행
- 메시징 시스템 이해
- 트랜잭션 아웃박스 패턴
- 배치 연동
- CDC

# **1. 별도 스레드로 실행하기**

비동기 연동에서 가장 쉬운 방법

## 1. 직접 새 스레드 생성

```java
// 방법 1: Thread 사용
new Thread(() -> pushClient.sendPush(pushData)).start();
return successResult(); // 푸시 발송을 기다리지 않고 리턴
```

## 2. 스레드 풀 이용

```java
ExecutorService executor = Executors.newFixedThreadPool(50);

// ...
public OrderResult placeOrder(OrderRequest req) {
    // 주문 생성 처리

    // 스레드 풀을 이용해서 푸시를 비동기로 발송
    executor.submit(() -> pushClient.sendPush(pushData));

    return successResult(); // 푸시 발송을 기다리지 않고 리턴
}

```

## 3. Async annotaion

Spring 프레임워크는 `@Async` 애너테이션으로 비동기 실행 기능을 제공한다

```java
@Async
public void sendPushAsync(PushData pushData) {
    pushClient.sendPush(pushData);
}

```

⇒

<aside>
🧐

## @Async는 내부적으로 어떻게 작동할까?

내부적으로 스레드 풀 기반의 비동기 실행을 구현

1. `@EnableAsync`로 비동기 지원 활성화
2. `@Async`가 붙은 메서드는 프록시가 가로챔
3. 프록시는 `TaskExecutor`에 메서드 실행을 제출
4. 메서드는 별도의 스레드에서 실행됨

## 1. **프록시 기반 처리**

Spring은 `@Async`가 붙은 메서드를 호출할 때 **프록시 객체**를 통해 처리

- `@Async`는 일반적으로 AOP기반으로 작동
- 해당 메서드는 실제로는 Spring이 생성한 프록시를 통해 호출
- 프록시는 비동기 실행을 위한 래퍼 역할

---

## 2. **스레드 풀(TaskExecutor) 사용**

비동기 처리를 위해 `TaskExecutor`를 사용

- 디폴트: `SimpleAsyncTaskExecutor`... but
- 사용성능이나 제어를 위해 일반적으로 `ThreadPoolTaskExecutor`를 Bean으로 등록해 사용

```java
@Configuration
@EnableAsync
public class AsyncConfig {
    @Bean(name = "asyncExecutor")
    public Executor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(5);
        executor.setMaxPoolSize(10);
        executor.setQueueCapacity(100);
        executor.setThreadNamePrefix("AsyncThread-");
        executor.initialize();
        return executor;
    }
}
```

```java
@Service
public class MyService {
    @Async("asyncExecutor")
    public void doAsyncTask() {
        // 이 메서드는 별도의 스레드에서 실행됨
    }
}
```

## 3. **리턴 타입에 따른 처리 방식**

- `void`: 결과를 받지 않음, 단순 fire-and-forget
- `Future<T>` / `CompletableFuture<T>` / `ListenableFuture<T>`: 결과를 비동기적으로 받을 수 있음

```java
@Async
public CompletableFuture<String> asyncMethod() {
    return CompletableFuture.completedFuture("Hello");
}
```

## 4. **제약사항**

- self-invocation은 비동기화되지 않음: 프록시가 작동하지 않기 때문
- `@EnableAsync`가 선언되지 않으면 작동하지 않음
- Bean 등록되어 있는 클래스여야 함 (예: `@Service`, `@Component` 등
</aside>

<aside>
🧐

### self-invocation은 왜 프록시가 작동하지 않을까?

Spring AOP는 **프록시 기반이기 때문…**

```java
@Service
public class MyService {
    @Async
    public void asyncMethod() {
        // 비동기 실행
    }

    public void caller() {
        asyncMethod(); // ❌ self-invocation
    }
}

```

- `MyService`는 프록시 객체로 감싸져 있고,
- 외부에서 `myService.asyncMethod()`로 호출하면 프록시가 개입해서 비동기 실행
- 하지만 `caller()` 안에서 `asyncMethod()`를 호출하면, 이건 프록시를 거치지 않고 실제 객체(this)를 통해 호출되기 때문에 비동기로 실행되지 않는다

외부 호출:  client → [Proxy(MyService)] → asyncMethod() ✅ (비동기 실행됨)

내부 호출:  this.caller() → this.asyncMethod() ❌ (비동기 아님)

# 해결 방법: 간단! 프록시를 타도록 하면 된다

1. 클래스를 나눠서 프록시를 타도록 하면 된다… ⇒ 이 방법이 더 코드가 읽기 좋고 개념이 명료하게 분리된 것 같아 마음에 듦

```java
@Service
public class AsyncService {
    @Async
    public void asyncMethod() {
        // 비동기 실행
    }
}

@Service
public class MyService {
    private final AsyncService asyncService;

    public MyService(AsyncService asyncService) {
        this.asyncService = asyncService;
    }

    public void caller() {
        asyncService.asyncMethod(); // ✅ 비동기 실행됨
    }
}

```

1. ApplicationContext 이용해 자신을 주입

```java
@Component
public class MyService {
    @Autowired
    private ApplicationContext context;

    @Async
    public void asyncMethod() { }

    public void caller() {
        context.getBean(MyService.class).asyncMethod(); // ✅ 프록시 경유
    }
}
```

</aside>

@Async 애노테이션을 사용할 때는 메서드 이름에 비동기 실행과 관련된 단어를 추가하는 것이 좋다

그 메서드를 이용하는 쪽에서 비동기라는것을 알아채기 힘들기 때문이다

결과를 기다리지 않고 리턴해버릴수도 있고

의미없는 try-catch 작성도 가능해진다

```java
public OrderResult placeOrder(OrderRequest req) {
    // 주문 생성 처리
    pushService.sendPush(pushData); // => 이게 비동기인지 동기인지 알아차릴 수 없어요!~
    return successResult(...); // 푸시 발송을 기다리지 않고 리턴
}

```

## **2. 예외 처리**

비동기로 실행되기 때문에 `try-catch` 블록이 호출자에 영향을 주지 않는다.

⇒ 이유 : 다른 스레드에서 터진 예외가 해당 스레드로 다시 전파되지 않기 때문임…

비동기 내부에서 직접 예외 처리해야 한다.!!! 주의점

```java
@Async
public void sendPushAsync(PushData pushData) {
    try {
        pushClient.sendPush(pushData);
    } catch (Exception e) {
        // 재시도, 로깅 등
    }
}
```

예외가 전파되지 않으면 다음과 같은 문제가 생길 수 있다…

<aside>
🧐

### 롤백이 안 됨

예외가 발생하는데도 이상하게 롤백이 안 되었던 경우

코드에서는 `@Transactional`을 이용해 트랜잭션 처리를 했고,

코드 중간에 실행되는 메서드에서 **예외**가 **발생**했지만 **트랜잭션이 롤백되지 않고 커밋됨**

**원인: 코드 중간에 실행한 메서드가 비동기로 실행되어 예외가 스레드에 직접 전파되지 않았던 것**

별도 스레드로 실행하는 메서드를 **같은 스레드**에서 실행되도록 수정해서 해결

 **트랜잭션 범위 안에서 비동기 코드 실행할 때는 트랜잭션 연동 여부에 주의…**

⇒ 나의 생각: 예외처리를 같이 해야 하는 단위별로 동기로 묶는것이 좋겠다!

</aside>

<aside>
🧐

## 스레드와 메모리

스레드는 자체적으로 일정 크기의 메모리를 사용

10만 개의 푸시 메시지를 비동기로 발송 ⇒  10만 개의 스레드를 생성

만약 스레드 1개가 사용하는 메모리가 256KB라면 10만 개 스레드를 생성하는 데만 약 24GB의 메모리가 필요

10만 개의 스레드를 생성하면 시간도 오래 걸린다. 

스레드 스케줄링에 많은 CPU 시간을 써서 실행 시간이 매우 느려질 수 있다

## ⇒ 스레드 풀의 등장!!!

스레드 풀을 사용하면 스레드의 일정 개수를 유지할 수 있어 메모리 사용량도 일정하게 유지

미리 스레드를 생성해두고 스레드를 재사용하는 시간도 단축됨

물리적 한계: 생성한 스레드 개수보다 더 많은 작업을 동시에 실행하려면 일부 작업은 완료되기 전까지 대기해야 함

비동기로 실행할 코드가 외부 API 호출이나 DB 연동 같은 네트워크 I/O 작업이라면

## ⇒  Java 가상스레드, Go 고루틴

가상 스레드나 고루틴은 실제 네이티브 스레드(OS 스레드)가 아닌 컨테이너에서 관리되는 경량 스레드

경량 스레드로 **적은 메모리를 사용**

</aside>

<aside>
🧐

## Java 가상스레드, Go 고루틴 vs 코루틴 의 설계 철학은 뭐가 다를까?

### Java Virtual Thread (Project Loom)

기존 블로킹 코드를 그대로 유지하면서 동시성도 잡자! 

by Java의 **보수적 진보(열린교회닫힘) 철학**

- 기존 코드를 거의 안 바꾸고도 동시성 향상 가능
- 블로킹 API도 OK
- **"개발자는 원래 하던 대로, 성능은 가상 스레드가 책임진다."**

목표: 기존 개발자들이 `Thread.sleep()`이나 JDBC 같은 **블로킹 API를 그대로 사용**하면서도 수만 개의 동시 작업을 처리 가능하게 만들자.

Java의 Virtual Thread는 진짜 `Thread`처럼 보이지만, **JVM이 직접 스케줄링하고 재사용하는 경량 스레드**

레거시 친화적 + 대규모 동시성이라는 두 마리 토끼를 잡으려는 시도

## Go Goroutine

병렬성 자체를 언어의 기본으로 설계한 혁신적 접근

동시성을 당연하게! 모든 코드는 병렬 실행 기본값! 

by Go의 **간결함과 병렬성 최우선 철학**

- 병렬성 = 기본 철학
- 동시성 코드를 쉽게 쓰게 하고, Go 런타임이 복잡한 건 책임짐
- **"동시성은 언어와 런타임 레벨의 기본 기능이다."**

Go에서는 함수 앞에 `go`만 붙이면 병렬 실행!

```java
go fetchData()

```

Goroutine은 매우 가볍고, Go 런타임이 자체적으로 **수십만 개를 M:N 매핑으로 스케줄링**

채널, 셀렉트 같은 동시성 도구로 안전한 데이터 전달을 유도

## Kotlin Coroutine

개발자에게 선언적 제어권을 줘서 가독성과 구조화를 지향

동시성을 프로그래머가 명시적으로 제어하고, 가독성과 유지보수를 높이자 

by Kotlin의 **표현력 + 안전성 철학**

- 코드를 읽을 때 흐름이 눈에 보이게 구성
- 직관적이지만 구조적 코루틴 철학을 따르지 않으면 금방 무너짐
- **동시성을 선언적이고 구조적으로 설계하자**

`suspend` 키워드로 **명확하게 어디서 중단될 수 있는지 선언**

```java
suspend fun fetchData(): String
```

Coroutine은 경량 스레드지만, 어디서 멈추고 다시 시작하는지 **컴파일러가 추적**

개발자가 CoroutineScope, Job, Dispatcher 등을 **조립해서 흐름을 통제**

핵심 차이점

자바 가상스레드랑 고루틴은 **개발자 경험을 바꾸지 않고 성능 향상 ⇒ 개발자가 신경쓸 일이 거의 없음**

코루틴은 병렬성과 비동기를 개발자가 명시적으로 설계하고 제어하는 방식 ⇒ 개발자가 세세하게 신경써야함, 책임 큼

비동기와 병렬성을 개발자가 직접 설계하되, 안전하고 가독성 있게

</aside>

<aside>
🧐

### 내 생각

역시 트렌드는 다시 개발자가 직접 깔끔하게 제어하는 것인 것 같다

스레드 제어 : 자바 경량스레드 고루틴 알아서 ⇒ 코루틴으로 개발자가 직접

메모리 제어 : Java Python 알아서 ⇒ Rust 소유권으로 개발자가 직접

</aside>

# 3. 메시징 시스템

```java
시스템 A → 메시지 생성/전송 → [메시징 시스템] → 메시지 전달 → 시스템 B
```

### 장점

- 두 시스템이 서로 영향을 주지 않는다 ⇒ 연동 시스템 장애 전파 등으로 고통받았던 것을 생각하면… 결합도는 낮을수록 좋다
    - 시스템 B의 성능이 저하되더라도 시스템 A는 영향을 받지 않고 메시지를 메시징 시스템에 등록

- 확장이 용이
    - 시스템 C에다가도 전송하고 싶으면 그냥 연결만 추가하면 됨
    - 코드를 바꿀 필요가 전혀 없음

<aside>
🧐

### pub/sub 구조

</aside>

<aside>
🧐

### 메시지 큐들의 차이점~

### 카프카를 고를 때

- **높은 처리량을 자랑한다.** 초당 백만 건 이상의 메시지를 처리할 수 있다.
- **수평 확장이 용이하다.** 서버(브로커), 파티션, 소비자를 늘리면 된다.
- **카프카는 메시지를 파일에 보관하여 메시지가 유실되지 않는다.**
- **1개의 토픽에 여러 파티션을 가질 수 있는데, 파티션 단위로 순서를 보장한다.** 하지만 토픽 수준에서는 순서가 보장되지 않는다.
- **소비자는 메시지를 언제든지 재처리할 수 있다.**
- **풀(pull) 모델을 사용한다.** 소비자가 카프카 브로커에서 메시지를 읽어 가는 방식이다

### 래빗MQ

- 클러스터를 통해 처리량을 높일 수 있다. 단, 카프카보다 더 많은 자원을 필요로 한다.
- 메모리에만 메시지를 보관하는 큐 설정을 사용하면 장애 상황 시 메시지가 유실될 수 있다.
- 메시지는 큐에 등록된 순서대로 소비자에 전송된다.
- 메시지가 소비자에 전달됐는지 확인하는 기능을 제공한다.
- **푸시(push)** 모델을 사용한다. 래빗MQ 브로커가 소비자에 메시지를 전송한다. 소비자의 성능이 느려지면 큐에 과부하가 걸려 전송 지연이나 장애가 발생할 수 있다.
- AMQP, AMQMP, STOMP 등 여러 프로토콜을 지원하고, 게시/구독 패턴뿐만 아니라 요청/응답, 절대 경로 패턴도 지원한다. 또한 우선순위를 지정해서 처리 순서를 변경할 수도 있다.

### 레디스 pub/sub

- 메모리를 사용하므로 지연 시간이 짧고, 래빗MQ 대비 처리량이 높다.
- 구독자가 없으면 메시지가 유실된다.
- 기본적으로 영구 메시지를 지원하지 않는다.
- 모델이 단순해서 사용하기 쉽다.
</aside>

<aside>
🧐

카프카의 pull 모델 ⇒ 뉴스피드 시스템 설계 공부할때 공부한 내용인가?!

### 팬아웃이 뭔데?!

fanout의 fan은 부채!

```
 중심에서
    ↓
  요청 하나
   / | \\
  /  |  \\
  서비스1 서비스2 서비스3
```

부챗살처럼 퍼져나간다~는 의미에서

팬아웃 모델은 두가지 모델

- 쓰기 시점에 팬아웃(fanout-on-write, push)
- 읽기 시점에 팬아웃(fanout-on-read, pull)

### fanout-on-write

새로운 포스팅을 기록하는 시점에 뉴스 피드를 갱신한다

포스팅이 완료되면 해당 사용자의 캐시에 해당 포스팅을 기록한다

- 장점
    - 뉴스피드가 실시간으로 갱신됨, 친구들한테 바로 전송됨
    - pre-computed, 이미 뉴스피드가 갱신되어있어서 읽을때 계산할 필요가 없어서 빠르다
    - 사용자가 뉴스피드를 확인할 때는 이미 준비된 데이터를 바로 보여주기만 하면 돼서 훨씬 빠르다
- 단점
    - 친구가 많은 사용자의 경우 갱신시 많은 시간이 소요된다 ⇒ 핫키 문제
    - 서비스를 자주 이용하지 않는 사용자의 피드까지 갱신해야 하니까 컴퓨팅 자원이 낭비된다

### fanout-on-read

피드를 읽어야 하는 시점에 뉴스 피드를 갱신한다

on-demand(요청 기반)모델

사용자가 본인 홈페이지나 타임라인을 로딩하는 시점에 새로운 포스트를 가져오게 된다

- 장점
    - 비활성화된 사용자, 접속이 드문 사용자는 이 모델이 유리함
    - 로그인시까지 컴퓨팅 자원 소모가 없음
    - 핫키 문제 x ⇒ 데이터를 친구 각각에 푸시하지 않으므로
- 단점
    - 뉴스피드를 읽는데 많은 시간이 소요된다

# Kafka의 pull 모델 ≠ fanout-on-read 지만… 좀 비슷하다 생각

| 항목 | 🔔 **Push 방식** | 🪝 **Pull 방식** |
| --- | --- | --- |
| **동작 방식** | 브로커가 소비자에게 **자동으로 메시지를 전달** | 소비자가 브로커에 **직접 요청해 메시지를 가져감** |
| **주도권** | 브로커 주도 | 소비자 주도 |
| **장점** | - 실시간 알림에 유리- 빠른 반응성 | - 소비자 속도 조절 가능- 백프레셔 대응 유리 |
| **단점** | - 소비자 느리면 큐 과부하- 제어 어려움 | - 지연 가능성 있음- 실시간성 떨어질 수 있음 |
| **대표 시스템** | - **RabbitMQ** (AMQP)- **Redis Pub/Sub**- Firebase FCM | - **Kafka**- **AWS SQS (Long Polling)**- Kinesis |
| **적합한 용도** | - 실시간 알림, 이벤트 브로드캐스트, 즉시 응답형 시스템 | - 로그 수집, 뉴스피드, 비동기 동기화, 스트리밍 분석 등 |
| **과부하 대응력** | 낮음 – 계속 밀어넣음 | 높음 – 소비자가 받을 준비됐을 때만 가져감 |
| **메시지 순서 보장** | 일반적으로 큐 단위 순서 보장 (RabbitMQ 등) | 파티션 단위 순서 보장 (Kafka) |

</aside>

### 메시지 생성 측 고려사항

메시지 유실 시

- 무시
- 재시도 → 메시지마다 고유 식별자 사용, 소비자가 중복 메시지 여부 판단하는데 도움이 됨
- 실패 로그 → 후처리에 사용

### DB 트랜잭션이 잘못되었지만 메시지가 전송되는 사례

```mermaid
sequenceDiagram
    participant 고객
    participant 주문서비스
    participant DB
    participant 메시징시스템
    participant 알림서비스

    고객->>주문서비스: 1. 요청
    주문서비스->>DB: 1.1 트랜잭션 시작
    주문서비스->>DB: 1.2 DB 변경
    주문서비스->>메시징시스템: 1.3 메시지 전송
    메시징시스템->>알림서비스: 1.3.1 메시지 전파
    주문서비스->>DB: 1.4 DB 변경
    DB-->>주문서비스: 1.5 변경 실패
    주문서비스->>DB: 1.6 트랜잭션 롤백
    주문서비스->>고객: 1.7 에러 응답
    알림서비스->>고객: 1.3.1.1 주문 안내 푸시 발송

```

1.4 단계에서 DB 변경에 실패해서 트랜잭션을 롤백했지만 메시지는 트랜잭션 롤백 전인 1.3 단계에서 메시징 시스템으로 전송됐다

1. 구조 개선
2. 아웃박스패턴

### 글로벌 트랜잭션과 메시지 연동

개념 : 여러 DB를 하나의 트랜잭션으로 묶어서 처리, 2단계 커밋(2-Phase Commit) 2PC 사용

단점 : 성능이 느려짐

성능 이슈 ⇒ 글로벌 트랜잭션이 반드시 필요한 상황이 아니라면 DB 처리와 메시지 연동을 묶지 말자

DB에 데이터를 반영한 뒤에 메시지를 전송하면 유실 없이 보내고 싶다면, 그보다 뒤에서 살펴볼 트랜잭션 아웃박스 패턴을 검토

### 메시지 소비 측 고려 사항

- 동일 메시지 중복 처리
    - 메시지 생산자가 같은 데이터를 가진 메시지를 메시징 시스템에 두 번 전송
    - 소비자가 메시지를 처리하는 과정에서 오류가 발생해서 메시지 재수신

해결 : **멱등성**을 갖도록 API를 구현 ⇒ 하나의 예시 : 메시지에 고유한 ID를 부여해서 이미 처리했는지 여부를 추적
이미 처리한 메시지는 다시 처리하지 않고 무시

메시지를 처리했는지는 보통 DB 테이블에 기록하거나 메모리 집합(Set)으로 관리
메모리로 관리할 때는 메모리 부족 에러가 발생하는 것을 막기 위해 일정 개수의 메시지 ID만 유지

### 이벤트와 커맨드

| 이벤트 | 커맨드 |
| --- | --- |
| 주문완료 | 포인트 지급하기 |
| 로그인에 실패함 | 로그인을 차단하기 |
| 상품 정보가 변경됨 | 배송 완료 문자 발송하기 |

이벤트 : 상태(데이터) 변경

커맨드 : 무엇인가를 요청

[학습 서비스] → (포인트 지급 요청) → [메시징 시스템] → (포인트 지급 요청) → [포인트 서비스]
커맨드 메시지는 메시지를 처리할 수신자가 정해져 있다.

이벤트 메시지는 메시지를 수신하는 소비자가 정해져 있지 않다. 

해당 이벤트에 관심 있는 소비자들이 모두 수신해서 알맞게 처리

### 궁극적 일관성

일관성 모델 중 하나로,

주로 분산 시스템에서 데이터 복제를 할 때 사용

즉시가 아닌 일정 시간이 지난 후에 일관성이 맞춰지는 특성 ⇒ MongoDB!

비동기 메시징 방식도 이 궁극적 일관성과 유사

배송 서비스에서 배송 상태를 '완료'로 변경

해당 변경 내용이 메시지를 통해 주문 서비스로 전달되기 전까지는 주문 서비스의 상태는 여전히 '배송 중'

이처럼 배송 완료 메시지가 전달되기 전까지는 두 시스템 간의 상태가 서로 불일치

## **트랜잭션 아웃박스 패턴**

### **정의**

DB 트랜잭션과 함께 메시지를 안전하게 발송하기 위한 패턴.

트랜잭션 커밋과 함께 메시지를 **아웃박스 테이블**에 저장하고,

중계 서비스가 이를 읽어 메시징 시스템에 전송.

### **처리 흐름**

```
[System A] → [DB] → [Outbox Table] → [CDC or 중계 프로세스] → [Messaging System]

```

DB 트랜잭션 범위에서 아웃박스 테이블에 메시지 데이터를 추가하므로 메시지 데이터가 유실되지 않는다.

트랜잭션을 롤백하면 메시지 데이터도 함께 롤백되므로 잘못된 메시지 데이터가 전송될 일도 없다.

- **DB 트랜잭션 내에서** 메시지를 아웃박스 테이블에 저장하면, 트랜잭션이 롤백될 때 함께 롤백됨 → 잘못된 메시지 전송 방지
- **중계 프로세스**는 주기적으로 메시지를 조회하여 메시징 시스템에 전송
- 전송 성공 시 상태를 전송 완료로 변경
- **중간 실패 시 전송 중단** → 순서 보장 목적

```java
// 이 메서드를 주기적으로 호출해서 메시지를 전송
public void processMessages() {
    // 아웃박스 테이블에서 대기 메시지 데이터를 순서대로 조회함
    List<MessageData> waitingMessages = selectWaitingMessages();

    for (MessageData m : waitingMessages) {
        try {
            sendMessage(m); // 메시지를 전송함
            markDone(m.getId()); // 발송 완료 표시함
        } catch (Exception ex) {
            handleError(ex); // 메시지 발송에 실패할 경우 후속 처리
            break; // 에러가 났을 때 멈춤. 이유는 순서대로 발송하기 위함
        }
    }
}
```

### **아웃박스 테이블 구조 예시**

| **컬럼** | **타입** | **설명** |
| --- | --- | --- |
| id | bigint | PK, 순차 증가 값 |
| messageId | varchar | 메시지 고유 ID |
| messageType | varchar | 메시지 타입 |
| payload | clob | 메시지 데이터 |
| status | varchar | WAITING, DONE, FAILED |
| failCount | int | 실패 횟수 |
| occurredAt | timestamp | 메시지 발생 시간 |
| processedAt | timestamp | 처리 시간 |
| failedAt | timestamp | 마지막 실패 시간 |

<aside>
🧐

retry, backoff, dead letter queue…

- **Retry**: 메시지 전송 실패 시 일정 횟수까지 자동 재시도하여 일시적 오류를 극복
- **Backoff**: 재시도 사이에 점점 늘어나는 지연(예: 1초 → 2초 → 4초 등)으로 시스템 과부하를 방지
- **Dead Letter Queue**: 재시도 후에도 실패한 메시지를 따로 보관해 시스템 오염을 막고 운영자가 추후 확인 가능하게 함
</aside>

# **배치 전송**

1. DB에서 전송할 데이터를 조회한다.
2. 조회한 결과를 파일로 기록한다.
3. 파일을 연동 시스템에 전송한다
- FTP/SFTP/SCP 등으로 전송
- JSON, 구분자, 고정 길이 형식 등 사용

정해야 할 것

- 파일 형태
- 송신 주체
- 시간
- 경로

## 파일 형태

### 구분자 방식

각 값을 특정 문자로 구분하는 방식(특수문자)

구현이 간단하고 파일 속도도 빨라서 널리 사용

### 키-값 쌍 방식

이름과 값을 쌍으로 묶음

각 쌍은 공백 문자로 구분

위치에 관계없이 어떤 값인지 알 수 있다는 장점

이름까지 포함되므로 첫 번째 형식에 비해 데이터 크기가 커짐

### JSON 방식

파일 이름, 형식을 지키기 위한 콤마, 큰따옴표, 콜론 등의 문자를 포함하면서 데이터 크기가 더 커짐…

⇒ 엑셀 내려받기가 우리는 DTO(JSON) 형식으로 되어있어서… 그거 모의면접에서 누가 물어보심

## 송신 주체

[파일 생성 시스템] → 업로드함 → [파일 소비 시스템]
[파일 생성 시스템] ← 다운로드함 ← [파일 소비 시스템]

배치 파일은 데이터 누락 등 오류에 대응할 수 있는 시간을 벌기 위해 근무가 시작되는 오전 시간대에 전송을 처리할 때가 많다.

하지만 생산자 시스템이 글로벌 서비스라면 국내 시간대가 아닌 다른 시간대를 기준으로 파일을 받아야 할 때도 있다.

이 경우 생산자 시스템이 보내줄 수 있는 시간에 맞춰 소비자 시스템의 처리 시간을 변경해야 한다.

<aside>
🧐

예전에도 궁금했는데 how?

</aside>

경로와 파일 이름 규칙도 맞춘다.

한 시스템이 여러 서브시스템으로부터 파일을 받을 수 있는데, 이 경우 파일의 저장될 경로나 이름이 충돌하지 않도록 규칙을 정한다.

### 생산자 → 소비자 업로드

소비자는:

- 지정한 경로에 파일이 존재하는지 확인한다.
- 파일이 존재하면 파일로부터 데이터를 읽어온다.
- 파일이 없으면 일정 시간 후 처리한다.
- 읽어온 데이터를 시스템에 반영한다.
- 처리를 완료한 파일은 다른 폴더로 옮긴다.(파일이 중복 처리되는 것 방지)

### 배치처리 방식 2. API를 이용(파일 대신)해서 데이터를 일괄로 전송

API를 사용하면 파일 생성, 파일 전송, 후처리 과정이 없으므로 관리가 단순해지는 장점

데이터 크기가 작거나 처리 항목이 적을 때 API를 이용한 데이터 전송 방식을 고려

### 배치처리 방식 3. 읽기 전용으로 DB를 여는 것

같은 조직 내에서 데이터를 전달, 개발 시간 부족할때

<aside>
🧐

## 책 내용

📌 Column: DB로 연동하기

한 10년 전 일이다. 쇼핑 서비스와 택배 시스템을 연동하는 업무를 담당한 적이 있다. 배송 요청 데이터를 택배 시스템에 전송하기 위해 매일 명단 문서를 요청했다. API 같은 문서를 기대했는데, DB IP, 계정, 테이블 형식서를 담은 문서가 왔다. 배송 요청 데이터를 해당 테이블에 추가하는 방식이었다. 배송 변경 내용을 담은 테이블도 있었다. 배송 상태가 바뀔 때마다 해당 테이블에 데이터가 추가되는 형태였다.

이렇게 레거시 시스템과 연동할 땐 보안 이슈나 시스템 성능 이슈로 인해 DB로 연동해야 할 때가 있다. DB로 연동하는 게 선호될 수 있지만, DB 테이블을 API 방식처럼 쓰게 되면, 연동 구현 방식이 다를 뿐이다. 필자는 HTTP 기반의 API를 선호하지만 각자 사정이 있다고 생각한다.

### 내 생각

면접에서 메시지 큐를 빼서 아키텍쳐 구현해보라는 말을 듣는다면 원시적으로 이런 방법을 얘기할 수 있겠다..?

</aside>

# **CDC (Change Data Capture)**

데이터베이스의 변경 사항을 추적하여 메시지나 타 시스템에 전파하는 패턴.

### **구성 요소**

```
[DB] → [CDC 처리기] → [Messaging System or Target System]

```

<aside>
🧐

 CDC 도구 예시(Debezium 등) ⇒ 데이터 변경 이력 로그 생성에도 쓸 수 있지 않을까?
실시간성이 중요한 것 같지도 않은 작업인데… 그냥 저거 쓰고 배치를 돌리면..?

</aside>

### **전파 방식**

- **그대로 전파**: DB간 동기화 등
- **변환 후 전파**: 통지 시스템 등

### **장점**

- 기존 시스템 수정 없이 타 시스템과 연동 가능
- Kafka 등과 함께 사용하여 확장성 확보

<aside>
🧐

### CDC와 데이터 위치 기록

CDC 처리기는 변경 데이터를 **어디까지 처리했는지 기록해야** 함

**MySQL**은 바이너리 로그(binlog)를 이용해서 CDC를 구현

각 로그 항목은 변경된 데이터와 **로그 파일에서의 위치(포지션)** 값을 갖는다.

위치 기록 ⇒  CDC 처리기 재시작 ⇒ 마지막으로 조회한 로그부터 읽기 가능

이 위치를 기록하지 않으면 마지막 로그 데이터부터 읽어와야 하는데,

이 경우 **CDC 처리기를 재시작하는 시간 동안 발생한 변경 데이터를 놓치게 됨**

1. CDC 처리기 실행 → 마지막 처리 위치: binlog-23, offset 42123
2. 시스템 꺼짐
3. 재시작 후 → 바로 offset 42123부터 이어서 처리 → 데이터 손실 없음 ✅

1. CDC 처리기 실행 중

1. 장애 발생 → 꺼짐
2. 재시작 → binlog의 **맨 마지막**부터 시작함 😨
→ 꺼져 있던 사이의 변경사항 다 놓침 ❌
</aside>

<aside>
🧐

### CDC가 유용할 때

- 신규 주문 시스템 데이터를 기존 시스템에 전파해야 하는 요구가 생김.
- 하지만 신규 시스템 개발자는 코드가 복잡하고 일정이 없어 연동 코드 추가를 거부함.
- 그래서 **DB 변경만 감지하는 CDC 방식**을 선택해 코드 수정 없이 문제 해결.
- CDC 처리기가 DB 변경을 감지해 Kafka에 메시지를 발행함.
- 소비자 시스템들은 Kafka 메시지를 받아 필요한 동기화를 수행함.

⇒ CDC로 해결!!!

신규 주문 시스템의 코드를 수정하지 않고도

**CDC를 사용해 타 시스템에 관련 데이터를 전파**

연동 대상 시스템이 2개였고, 서로 데이터를 처리하는 속도가 달라 중간에 카프카 도입

CDC로 연동 기능을 구현한 덕분에 신규 주문 시스템 개발 일정에 주는 영향을 최소화

</aside>
